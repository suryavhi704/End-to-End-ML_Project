{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8279846",
   "metadata": {},
   "source": [
    "## Importing required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f6dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe8af94",
   "metadata": {},
   "source": [
    "## Data Augmentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916ca2e",
   "metadata": {},
   "source": [
    "Training image creation for cat image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c58d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation: Due to less data we are using data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\cat image.png\")  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir=r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\train\\cat\", save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41336eb1",
   "metadata": {},
   "source": [
    " Training image creation for dog image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d1e885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation: Due to less data we are using data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\dog image.jpg\")  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir=r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\train\\dog\", save_prefix='dog', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8a830b",
   "metadata": {},
   "source": [
    "Testing image creation for cat image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed53a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation: Due to less data we are using data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\cat image.png\")  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir=r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\test\\cat\", save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4158530f",
   "metadata": {},
   "source": [
    "Testing image creation for dog image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13c47f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation: Due to less data we are using data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img\n",
    "\n",
    "dataaug = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.5,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img(r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\dog image.jpg\")  \n",
    "pic = img_to_array(img) \n",
    "pic = pic.reshape((1,) + pic.shape)\n",
    "\n",
    "i = 0\n",
    "for x in dataaug.flow(pic, batch_size=1,\n",
    "                          save_to_dir=r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\test\\dog\", save_prefix='dog', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "326b6dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the Training set and Test set\n",
    "train = ImageDataGenerator(rescale = 1./255)\n",
    "test = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fe04bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 2 classes.\n",
      "Found 11 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = train.flow_from_directory(r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\train\",\n",
    "                                                 target_size = (100, 100),\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_data = test.flow_from_directory(r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\test\",\n",
    "                                            target_size = (100, 100),\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a085fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.6954 - val_accuracy: 0.9091 - val_loss: 0.3621\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.8182 - loss: 0.3408 - val_accuracy: 1.0000 - val_loss: 0.0511\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 0.0524 - val_accuracy: 1.0000 - val_loss: 0.0382\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0494 - val_accuracy: 1.0000 - val_loss: 0.0176\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 0.0260 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 4.4282e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 5.9802e-04 - val_accuracy: 1.0000 - val_loss: 1.6679e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 1.8995e-04 - val_accuracy: 1.0000 - val_loss: 7.7880e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 1.0000 - loss: 6.9695e-05 - val_accuracy: 1.0000 - val_loss: 4.4466e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13ceb813200>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Convolution2D(32,3,3,input_shape=(100,100,3),activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(128,activation='relu'))\n",
    "classifier.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer='adam',\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier.fit(train_data,epochs=10,validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c291fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "def predict(path,classifier):\n",
    "    predict = keras.utils.load_img(path, target_size = (100,100))   \n",
    "    predict_modified = keras.utils.img_to_array(predict)\n",
    "    predict_modified = predict_modified / 255\n",
    "    predict_modified = np.expand_dims(predict_modified, axis = 0)\n",
    "    final = classifier.predict(predict_modified)\n",
    "    print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5634a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "[[1.10053825e-05]]\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\cat image.png\" # cat image\n",
    "predict(path,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048ae2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "[[0.9999621]]\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\DELL\\Desktop\\image set cat_dog\\dog image.jpg\" # dog image\n",
    "predict(path,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3e02765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "classifier.save('clf.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
